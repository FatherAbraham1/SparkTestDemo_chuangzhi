SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/hadoop/workspace1/SparkDemo1/libs/spark-assembly-1.4.0-hadoop2.6.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/hadoop/workspace1/SparkDemo1/libs/spark-examples-1.4.0-hadoop2.6.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
16/05/04 18:07:40 INFO SparkContext: Running Spark version 1.4.0
16/05/04 18:07:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
16/05/04 18:07:41 INFO SecurityManager: Changing view acls to: hadoop
16/05/04 18:07:41 INFO SecurityManager: Changing modify acls to: hadoop
16/05/04 18:07:41 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(hadoop); users with modify permissions: Set(hadoop)
16/05/04 18:07:42 INFO Slf4jLogger: Slf4jLogger started
16/05/04 18:07:42 INFO Remoting: Starting remoting
16/05/04 18:07:42 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.3.8:45561]
16/05/04 18:07:42 INFO Utils: Successfully started service 'sparkDriver' on port 45561.
16/05/04 18:07:42 INFO SparkEnv: Registering MapOutputTracker
16/05/04 18:07:42 INFO SparkEnv: Registering BlockManagerMaster
16/05/04 18:07:42 INFO DiskBlockManager: Created local directory at /tmp/spark-eefa1334-c2c3-400c-9d3b-d467d018bb1d/blockmgr-09e154a7-a264-4ef0-afc0-162004be473e
16/05/04 18:07:42 INFO MemoryStore: MemoryStore started with capacity 1413.2 MB
16/05/04 18:07:42 INFO HttpFileServer: HTTP File server directory is /tmp/spark-eefa1334-c2c3-400c-9d3b-d467d018bb1d/httpd-4fc3fe3d-3916-4216-ab6b-070283a96822
16/05/04 18:07:42 INFO HttpServer: Starting HTTP Server
16/05/04 18:07:42 INFO Utils: Successfully started service 'HTTP file server' on port 35337.
16/05/04 18:07:42 INFO SparkEnv: Registering OutputCommitCoordinator
16/05/04 18:07:43 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
16/05/04 18:07:43 INFO Utils: Successfully started service 'SparkUI' on port 4041.
16/05/04 18:07:43 INFO SparkUI: Started SparkUI at http://192.168.3.8:4041
16/05/04 18:07:43 INFO AppClient$ClientActor: Connecting to master akka.tcp://sparkMaster@192.168.3.8:7077/user/Master...
16/05/04 18:08:03 INFO AppClient$ClientActor: Connecting to master akka.tcp://sparkMaster@192.168.3.8:7077/user/Master...
16/05/04 18:08:23 INFO AppClient$ClientActor: Connecting to master akka.tcp://sparkMaster@192.168.3.8:7077/user/Master...
16/05/04 18:08:43 ERROR SparkDeploySchedulerBackend: Application has been killed. Reason: All masters are unresponsive! Giving up.
16/05/04 18:08:43 WARN SparkDeploySchedulerBackend: Application ID is not initialized yet.
16/05/04 18:08:43 INFO SparkUI: Stopped Spark web UI at http://192.168.3.8:4041
16/05/04 18:08:43 INFO DAGScheduler: Stopping DAGScheduler
16/05/04 18:08:43 INFO SparkDeploySchedulerBackend: Shutting down all executors
16/05/04 18:08:43 INFO SparkDeploySchedulerBackend: Asking each executor to shut down
16/05/04 18:08:43 INFO AppClient$ClientActor: Connecting to master akka.tcp://sparkMaster@192.168.3.8:7077/user/Master...
16/05/04 18:08:43 ERROR OneForOneStrategy: 
java.lang.NullPointerException
	at org.apache.spark.deploy.client.AppClient$ClientActor$$anonfun$receiveWithLogging$1.applyOrElse(AppClient.scala:160)
	at scala.runtime.AbstractPartialFunction$mcVL$sp.apply$mcVL$sp(AbstractPartialFunction.scala:33)
	at scala.runtime.AbstractPartialFunction$mcVL$sp.apply(AbstractPartialFunction.scala:33)
	at scala.runtime.AbstractPartialFunction$mcVL$sp.apply(AbstractPartialFunction.scala:25)
	at org.apache.spark.util.ActorLogReceive$$anon$1.apply(ActorLogReceive.scala:59)
	at org.apache.spark.util.ActorLogReceive$$anon$1.apply(ActorLogReceive.scala:42)
	at scala.PartialFunction$class.applyOrElse(PartialFunction.scala:118)
	at org.apache.spark.util.ActorLogReceive$$anon$1.applyOrElse(ActorLogReceive.scala:42)
	at akka.actor.Actor$class.aroundReceive(Actor.scala:465)
	at org.apache.spark.deploy.client.AppClient$ClientActor.aroundReceive(AppClient.scala:61)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:516)
	at akka.actor.ActorCell.invoke(ActorCell.scala:487)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238)
	at akka.dispatch.Mailbox.run(Mailbox.scala:220)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:393)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
16/05/04 18:08:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36893.
16/05/04 18:08:43 INFO NettyBlockTransferService: Server created on 36893
16/05/04 18:08:43 INFO BlockManagerMaster: Trying to register BlockManager
16/05/04 18:08:43 INFO BlockManagerMasterEndpoint: Registering block manager 192.168.3.8:36893 with 1413.2 MB RAM, BlockManagerId(driver, 192.168.3.8, 36893)
16/05/04 18:08:43 INFO BlockManagerMaster: Registered BlockManager
16/05/04 18:08:43 ERROR SparkContext: Error initializing SparkContext.
java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext
	at org.apache.spark.SparkContext.org$apache$spark$SparkContext$$assertNotStopped(SparkContext.scala:103)
	at org.apache.spark.SparkContext.getSchedulingMode(SparkContext.scala:1501)
	at org.apache.spark.SparkContext.postEnvironmentUpdate(SparkContext.scala:2005)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:543)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at cn.wh.Test.Test.<clinit>(Test.java:35)
16/05/04 18:08:43 INFO SparkContext: SparkContext already stopped.
Exception in thread "main" java.lang.ExceptionInInitializerError
Caused by: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext
	at org.apache.spark.SparkContext.org$apache$spark$SparkContext$$assertNotStopped(SparkContext.scala:103)
	at org.apache.spark.SparkContext.getSchedulingMode(SparkContext.scala:1501)
	at org.apache.spark.SparkContext.postEnvironmentUpdate(SparkContext.scala:2005)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:543)
	at org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:61)
	at cn.wh.Test.Test.<clinit>(Test.java:35)
16/05/04 18:08:43 INFO DiskBlockManager: Shutdown hook called
16/05/04 18:08:43 INFO Utils: path = /tmp/spark-eefa1334-c2c3-400c-9d3b-d467d018bb1d/blockmgr-09e154a7-a264-4ef0-afc0-162004be473e, already present as root for deletion.
16/05/04 18:08:43 INFO Utils: Shutdown hook called
16/05/04 18:08:43 INFO Utils: Deleting directory /tmp/spark-eefa1334-c2c3-400c-9d3b-d467d018bb1d/userFiles-c4aa951f-c157-42f0-9d41-0e7d4d0ebcc0
16/05/04 18:08:43 INFO Utils: Deleting directory /tmp/spark-eefa1334-c2c3-400c-9d3b-d467d018bb1d/httpd-4fc3fe3d-3916-4216-ab6b-070283a96822
16/05/04 18:08:43 INFO Utils: Deleting directory /tmp/spark-eefa1334-c2c3-400c-9d3b-d467d018bb1d









http://www.blogjava.net/algz/articles/324727.html

